{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgq1azWYPnjsxuqpp5kDEp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork/"],"metadata":{"id":"ah4IHSl2jU9Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usAOCoSyhe3U"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets"]},{"cell_type":"code","source":["train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())"],"metadata":{"id":"SZhIZt-Thk8D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_dataset.train_data.size())\n","\n","print(train_dataset.train_labels.size())\n","\n","print(test_dataset.test_data.size())\n","\n","print(test_dataset.test_labels.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZLeZAnvXhk5D","executionInfo":{"status":"ok","timestamp":1643825003137,"user_tz":180,"elapsed":33,"user":{"displayName":"Luca Peres","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12015917659615222676"}},"outputId":"499145c3-3ccd-4ff8-8f35-58d64b79b703"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([60000, 28, 28])\n","torch.Size([60000])\n","torch.Size([10000, 28, 28])\n","torch.Size([10000])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n","  warnings.warn(\"train_data has been renamed data\")\n","/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n","  warnings.warn(\"train_labels has been renamed targets\")\n","/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n","  warnings.warn(\"test_data has been renamed data\")\n","/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n","  warnings.warn(\"test_labels has been renamed targets\")\n"]}]},{"cell_type":"code","source":["batch_size = 100\n","n_iters = 3000\n","num_epochs = n_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"metadata":{"id":"YFXTdchihk2T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RNNModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n","        super(RNNModel, self).__init__()\n","        # Hidden dimensions\n","        self.hidden_dim = hidden_dim\n","\n","        # Number of hidden layers\n","        self.layer_dim = layer_dim\n","\n","        # Building your RNN\n","        # batch_first=True causes input/output tensors to be of shape\n","        # (batch_dim, seq_dim, input_dim)\n","        # batch_dim = number of samples per batch\n","        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n","\n","        # Readout layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        # Initialize hidden state with zeros\n","        # (layer_dim, batch_size, hidden_dim)\n","        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n","\n","        # We need to detach the hidden state to prevent exploding/vanishing gradients\n","        # This is part of truncated backpropagation through time (BPTT)\n","        out, hn = self.rnn(x, h0.detach())\n","\n","        # Index hidden state of last time step\n","        # out.size() --> 100, 28, 10\n","        # out[:, -1, :] --> 100, 10 --> just want last time step hidden states! \n","        out = self.fc(out[:, -1, :]) \n","        # out.size() --> 100, 10\n","        return out"],"metadata":{"id":"1Ha7pRO7hkzT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_dim = 28\n","hidden_dim = 100\n","layer_dim = 1\n","output_dim = 10\n","\n","model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)"],"metadata":{"id":"TqJYBrckhkwj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"fgtugFKshktL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate = 0.01\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "],"metadata":{"id":"LdH_yt-mh2Bt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of steps to unroll\n","seq_dim = 28  \n","\n","iter = 0\n","\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        model.train()\n","        \n","        # Load images as tensors with gradient accumulation abilities\n","        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        # outputs.size() --> 100, 10\n","        outputs = model(images)\n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","          \n","            model.eval()\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","                # Load images to a Torch tensors with gradient accumulation abilities\n","                images = images.view(-1, seq_dim, input_dim)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs.data, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","                # Total correct predictions\n","                correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocTdHjU7h3LF","executionInfo":{"status":"ok","timestamp":1643825099202,"user_tz":180,"elapsed":78195,"user":{"displayName":"Luca Peres","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12015917659615222676"}},"outputId":"2738baee-7cfb-42e9-e769-b264df7afb88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration: 500. Loss: 2.302279233932495. Accuracy: 16.559999465942383\n","Iteration: 1000. Loss: 2.2936532497406006. Accuracy: 17.739999771118164\n","Iteration: 1500. Loss: 2.2707290649414062. Accuracy: 19.489999771118164\n","Iteration: 2000. Loss: 1.9751801490783691. Accuracy: 28.950000762939453\n","Iteration: 2500. Loss: 1.3024159669876099. Accuracy: 40.04999923706055\n","Iteration: 3000. Loss: 0.7790878415107727. Accuracy: 69.87000274658203\n"]}]}]}